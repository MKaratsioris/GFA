# Data Engineering Orientation Exam

## Getting Started

- **Fork** this repository under your own account
- Clone your forked repository to your computer
- Commit your progress frequently and with descriptive commit messages
- All your answers and solutions should go in this repository
- Take care of style guide
- Take care of the naming of classes, fields, variables, files, etc.

## Keep in mind

- You can use any resource online, but **please work individually**

- **Don't just copy-paste** your answers and solutions,
  you need to understand every line of your code
- **Don't push your work** to GitHub until your mentor announces
  that the time is up
- At the end of the exam push your solution to **GitHub**

## Overview

The aim of this project is to collect information about Airports in the world from different sources and analyze these data to create reports about airports. Create an ETL pipeline which collects information about Airports using Airflow (which is scheduled **every week**). Your job is to get data from REST API, transform and load it to a MSSQL database. Another source of data is dataset airports. Your job is to extract the data, transform and load them to the same MSSQL database. Create a new collection in MongoDB database and load the data there. The last part is to create some useful reports. Using SQL queries your task is to retrieve some info about airports. In MongoDB you should create other queries.   

You will be provided with **docker-compose file** which consists of Airflow, MSSQL and MongoDB containers (don't forget to create connection in Airflow for MSSQL). Your MongoDB database should be running on Atlas cloud, but you can create this database locally, it is up to your decision.

## ETL pipeline

Create a Python project which retrieves the data from [this API](https://restcountries.com/#api-endpoints-v3-list-of-codes) (find the endpoint that returns ALL countries) and load the data into MSSQL database (all fields). 

Store info to the MSSQL database under the table _countries_ with following columns:
- id (has to be autogenerated, integer)
- name ('common')
- iso2_code ('cca2')
- continent (1. element of the continents)

(In the brackets you find the exact fields that we are interested in.)
## Extract airports data, transform and load

Create an Airflow DAG which runs weekly, which extract data from airports dataset. Download the csv file from the [dataset](https://datahub.io/core/airport-codes) or use this url to [json file](https://pkgstore.datahub.io/core/airport-codes/airport-codes_json/data/9ca22195b4c64a562a0a8be8d133e700/airport-codes_json.json) (no need to download it) to extract the dataset. 

Your next job is to transform the dataset so we will be able to work with it:
- If gps_code of the airport is missing: drop the row
- if some fields are empty, fill it with zero.

_Hint: Make sure you have the same order of columns in the pandas Dataframe as in the MSSQL table._

After transforming, store the data into MSSQL table _airports_ with following columns:
- id (has to be autogenerated, integer)
- ident
- type
- name
- elevation_ft (integer)
- iso_country
- iso_region
- municipality
- gps_code
- iata_code
- local_code
- coordinates

These two dataset have something in common.
The relationship between the tables is: One country can have more airports, but one airport belongs only to one country!
You might need this information when joining the tables.

Amount of DAG tasks is up you. Because of inserting more then 40k rows, this task may take a while in Airflow.
(If you have performance issues during the load phase, you can limit the rows you load in the database.)

(Export the db from Azure Data Studio as csv. If you create the db locally, give us the query in a separate file.)

## Load data to MongoDB
Retrieve name, type, elevation_ft, iso_region, gps_code, local_code of airport and name, continent from countries and insert the result to MongoDB collection airports as separate documents.

## Create Reports

Your job is to create a separate project (Airflow DAG) which create some reports. 

Write the following SQL queries (you can just print the result):
- What are the top 10 highest airports based on the `elevation_ft` (with ties)?
- Which airports are located in Africa?
- Which airports local code start with 02? Return only name and local_code.
- What are the highest elevation_ft by continents?
- What is the count of airports that belongs to small_airport airport type?

Write the following Mongo queries (you can just print the result):
- Which airports are located in Europe? Return only name and continent and sort the result by elevation_ft in descending order.
- What is the count of airports that belongs to heliport airport type?

(Create a DAG and use pymongo. Export the db from MongoDB Compass as json.)
